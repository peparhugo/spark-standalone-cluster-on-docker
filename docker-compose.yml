---
# ------------------------------------------------------------------------------------
# -- Docs: https://github.com/andre-marcos-perez/spark-standalone-cluster-on-docker --
# ------------------------------------------------------------------------------------
version: "3.6"
volumes:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local
services:
  jupyterlab:
    image: andreper/jupyterlab:2.1.4-spark-2.4.4
    container_name: jupyterlab
    ports:
      - 8888:8888
    volumes:
      - shared-workspace:/opt/workspace
      - ./take-home-assignment/:/opt/workspace/take-home-assignment/
  spark-master:
    image: andreper/spark-master:2.4.4-hadoop-2.7
    container_name: spark-master
    ports:
      - 8080:8080
      - 7077:7077
    volumes:
      - shared-workspace:/opt/workspace
  spark-worker:
    image: andreper/spark-worker:2.4.4-hadoop-2.7
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=128m
      - SPARK_EXECUTOR_MEMORY=256m
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master